vectordb:
  - name: bge_small
    db_type: chroma
    client_type: persistent
    embedding_model: huggingface_baai_bge_small
    collection_name: huggingface_baai_bge_small
    path: ${PROJECT_DIR}/resources/chroma
  - name: rubert
    db_type: chroma
    client_type: persistent
    embedding_model: huggingface_cointegrated_rubert_tiny2
    collection_name: huggingface_cointegrated_rubert_tiny2
    path: ${PROJECT_DIR}/resources/chroma
  - name: mpnet
    db_type: chroma
    client_type: persistent
    embedding_model: huggingface_all_mpnet_base_v2
    collection_name: huggingface_all_mpnet_base_v2
    path: ${PROJECT_DIR}/resources/chroma
  - name: bge_m3
    db_type: chroma
    client_type: persistent
    embedding_model: huggingface_bge_m3
    collection_name: huggingface_bge_m3
    path: ${PROJECT_DIR}/resources/chroma
node_lines:
  - node_line_name: pre_retrieve_node_line
    nodes:
      - node_type: query_expansion
        strategy:
          metrics: [retrieval_f1]
          speed_threshold: 10
          top_k: 2
          retrieval_modules:
            - module_type: vectordb
              vectordb: bge_small
              embedding_batch: 256
        modules:
          - module_type: multi_query_expansion
            generator_module_type: vllm
            model: ["Qwen/Qwen2.5-1.5B-Instruct"]
            temperature: 0.7
  - node_line_name: retrieve_node_line
    nodes:
      - node_type: retrieval
        strategy:
          metrics: [retrieval_f1]
          speed_threshold: 10
        top_k: 2
        modules:
          - module_type: vectordb
            vectordb: bge_small
            embedding_batch: 256
      - node_type: passage_reranker
        strategy:
          metrics: [retrieval_f1]
          speed_threshold: 10
        top_k: 1
        modules:
          - module_type: sentence_transformer_reranker
            model_name: cross-encoder/ms-marco-TinyBERT-L2-v2
      - node_type: passage_compressor
        strategy:
          metrics: [retrieval_token_f1, retrieval_token_recall, retrieval_token_precision]
          speed_threshold: 10
        modules:
          - module_type: refine
            llm: openai
            model: gpt-3.5-turbo-16k
  - node_line_name: post_retrieve_node_line
    nodes:
      - node_type: prompt_maker
        modules:
          - module_type: long_context_reorder
            prompt:
              - "There is a passages related to user question. Please response carefully to the following question. \n\n Passage: {retrieved_contents} \n\n Question: {query} \n\n Answer the question. Think step by step."
      - node_type: generator
        strategy:
          metrics:
            - metric_name: bleu
            - metric_name: meteor
            - metric_name: rouge
            - metric_name: sem_score
              embedding_model: openai
          speed_threshold: 10
        modules:
          - module_type: vllm
            llm: "google/gemma-2b"
            temperature: 0
            max_tokens: 512